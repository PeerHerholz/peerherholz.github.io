[{"authors":["admin"],"categories":null,"content":"Ahoi hoi there and welcome to my website. My name is Peer and I\u0026rsquo;m currently a postdoctoral researcher\nin cognitive and computational auditory neuroscience partly affiliated with the Montréal Neurological Institute \u0026amp; Hospital (MNI) located at McGill University \u0026amp; with the International Laboratory for Brain, Music and Sound Research (BRAMS) which is jointly run by the Université de Montréal \u0026amp; McGill University. More precisely, I work in the Zatorre \u0026amp; NeuroDataScience: ORIGAMI labs. Additionally, I\u0026rsquo;m also affiliated with the Virtual Data Lab.\nI\u0026rsquo;m interested in how human and non-human brains, as well as machines process sounds, especially music, which I mainly investigate using fMRI and pattern analyses/computational approaches, but more and more also aided by EEG and behavior. Furthermore, I\u0026rsquo;m interested in the structure and organization of the human auditory pathway, as well as data analysis approaches (e.g., multimodal data integration, alignment methods \u0026amp; statistical learning). All of the above as open, transparent and reproducible as possible.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://peerherholz.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"Ahoi hoi there and welcome to my website. My name is Peer and I\u0026rsquo;m currently a postdoctoral researcher\nin cognitive and computational auditory neuroscience partly affiliated with the Montréal Neurological Institute \u0026amp; Hospital (MNI) located at McGill University \u0026amp; with the International Laboratory for Brain, Music and Sound Research (BRAMS) which is jointly run by the Université de Montréal \u0026amp; McGill University. More precisely, I work in the Zatorre \u0026amp; NeuroDataScience: ORIGAMI labs.","tags":null,"title":"Peer Herholz","type":"author"},{"authors":null,"categories":null,"content":"Given the importance and prominent role of music for the majortity of people out there, it\u0026rsquo;s quite hard to imaging lacking the ability to actually process or enjoy music. However, for people affected by amusia or musical anhedonia this is reality. While the first have difficulties perceiving and/or producing melodies (pitch) or rhythms (or both) (if you\u0026rsquo;re interested check this great in depth and comprehensive review by Isabelle Peretz), the latter show the incapacity of enjoying listening to music (great introduction, study and overview by Martínez-Molina et al.). Interestingly, upon a closer look these two show some sort of \u0026ldquo;double dissociation\u0026rdquo; in that people affected by amusica can and do enjoy music despite the aforementioned problems, whereas people affected by musical anhedonia have no difficulties in processing music (e.g. it\u0026rsquo;s structure). Hence, I\u0026rsquo;m very interested in both investigating possible models of explanation combining multimodal data with connectivity measures and multivariate approaches.\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"c97c8c409e884bc6a7b7c42ab93fbcf8","permalink":"https://peerherholz.github.io/project/disorder_music/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/disorder_music/","section":"project","summary":"What can 'disorders' of music processing tell us about its organization?","tags":["disorder music processing"],"title":"'Disorders' of music processing","type":"project"},{"authors":null,"categories":null,"content":"Our normal all day life is full of an ever changing and highly complex soundscape. How and during which time point during auditory perception those countless sound categories emerge in the cortical and subcortical auditory pathway is not only a very interesting, but also challenging question. For a quite a while I\u0026rsquo;m particulary fascinated by the cortical interaction of music, singing and language, which I investigate through combined MRI \u0026amp; EEG, anazlying subsequent data using different connectivity and machine learning approaches. Additionally, possible factors of influence such as musical training and handedness are an important part of this research question. The project\u0026rsquo;s github and OSF pages provide more information.\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"8d96bd48ef0a489c0b26c15afbbbf5b8","permalink":"https://peerherholz.github.io/project/auditory_processing/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/auditory_processing/","section":"project","summary":"How is music specialized in the human brain?","tags":["auditory processing"],"title":"Auditory processing","type":"project"},{"authors":null,"categories":null,"content":"Glasser at al. summarized it quite well in their 2016 \u0026ldquo;A Multi-modal Parcellation of Human Cerebral Cortex\u0026rdquo; paper when they were stating \u0026ldquo;In contrast to early visual and somatomotor cortex, parcellation of the early auditory cortex has proven much more challenging\u0026hellip;\u0026rdquo; (Suppl. 3, page 35, line 7-8 ). The robust and reliable localization and parcellation of the human auditory cortex, along with it\u0026rsquo;s functional principles has been the subject of a long-standing debatte with the vast amount of possible analyses that to can be applied to the variety of possible measurements adding yet another layer of complexity. Based on that I started developing ALPACA (OSF page here), an open-source python toolbox for the \u0026ldquo;Automated Localization and Parcellation of Auditory Cortex Areas\u0026rdquo; (full disclosure: I had the abbreviation first and then tried to come up with a fitting name, luckily that worked out pretty well) which will include experiment and analyses scripts for different paradigms (natural sounds \u0026amp; classic tone bursts) and approaches (structural parcellation, mapping of auditory ROIs from atlases, fMRI, EEG, searchlights, encoding, etc.). The respective parts can be combined as preferred and run as functions or fully automated via docker and/or as a BIDS app, hopefully helping folks with creating ROIs for their study and/or further advancing the investigation of the human auditory cortex.\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"80b75b9bfc3cc7e55ad96eb664e73a42","permalink":"https://peerherholz.github.io/project/auditory_system/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/auditory_system/","section":"project","summary":"How is the auditory system organized in the human brain?","tags":["auditory system"],"title":"Structure \u0026 function of the auditory system","type":"project"},{"authors":null,"categories":null,"content":"As music is as divers as mysterious to such an extent that it\u0026rsquo;s hard or nearly impossible to actually define it, I\u0026rsquo;m interested how music processing, especially perception, is shaped, how it can be described and possibly explained. To hopefully shed some light on this rather overwhelming question I investigate how human and non-human brains perceive and represent different music genres and how these representations can be explained based on auditory/music features, as well as conceptual and computational models. To do so I apply a broad range of methods, ranging from imaging (MRI \u0026amp; EEG) to behavior to artificial neural networks furthermore including important factors such as development (culture \u0026amp; music preference) and plasticity (musical training). You can find more information about this line of my research on the projects github or OSF page. Furthermore, I\u0026rsquo;m working, as a remote contributor, in Harvard\u0026rsquo;s music lab in the amazing Natinal History of Song project.\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"d3ea6363ddd359e5d403d0b038b7c3bf","permalink":"https://peerherholz.github.io/project/music_perception/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/music_perception/","section":"project","summary":"How do humans and machines perceive music?","tags":["music perception"],"title":"music perception","type":"project"},{"authors":null,"categories":null,"content":"I was once told that one doesn\u0026rsquo;t have to understand neuroscience methods and statistics in order to apply. While this is certainly true, it\u0026rsquo;s also certainly bad. Starting with very little method \u0026amp; zero programming skills everything was kinda overwhelming but at the same time fascinating. The combination of math, physics, informatics and biology amazed me and the more I read and gained practical experience the more I wanted to understand. I\u0026rsquo;m especially insterested in data management and quality control, non-standard experimental setups (e.g., naturalistic stimulation) and acquisition schemes (e.g., multiband, MT), processing steps (e.g., ICA, detrending), image registration, multi-modal measurements \u0026amp; data integretation, as well as multivariate analyses approaches (e.g., machine learning, encoding models). Furthermore, I\u0026rsquo;m working on pipeline creation / automization and cloud / hpc computing, recently setting up my first own server system.\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"999c0b255c10d987f4e9d97ac03b5e7c","permalink":"https://peerherholz.github.io/project/methods/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/methods/","section":"project","summary":"The statistical analysis - it's beautiful","tags":["tools auditory neuroscience"],"title":"neuroinformatics \u0026 methods","type":"project"},{"authors":null,"categories":null,"content":"Starting with the lack of details in the methods section of papers I was reading to no chance of having a look at the data or code (or sometimes even the whole publication) created some sort of frustration I found it hard to cope with. Hence, I\u0026rsquo;m trying to open up my daily research worklfow as much as possible throughout all stages using a variety of tools (great resource on how to get started can be found here). Through the support during my time as an \u0026ldquo;open science fellow\u0026rdquo; I was able to initiate the Open Science Initiative University of Marburg, an university wide organization fostering open science principles for example via hackrooms and hackathons (e.g. brainhacks), workshops (e.g. here), as well as general assistance and support (e.g. here). Additionally, I\u0026rsquo;m working on integrating comparably new and less know tools like open knowledge maps \u0026amp; scholia into research workflows and how to use virtualization software like docker \u0026amp; singularity for hustle free reproducibility and generalizabillity.\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"f8bb0155dd28142902d134b466cc0532","permalink":"https://peerherholz.github.io/project/open/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/open/","section":"project","summary":"How can (neuro)science be made more open \u0026 reproducible?","tags":["open reproducible science"],"title":"open \u0026 reproducible (neuro)science","type":"project"},{"authors":null,"categories":null,"content":"Fellow folks working in auditory neuroscience know the somewhat struggle that goes along with that line of research, especially within the realm of MRI: due to the nature of the stimulus experiments can be harder to implement, take way longer SNR is far from being good and whatnot (make sure to check Jonathan Peelle\u0026rsquo;s amazing review on that topic). Hence, working on how experiments can be improved is (like usual) as much as important as actually doing them. Besides the already mentioned ALPACA toolbox, I\u0026rsquo;m therefore also very interested in improving settings for auditory neuroscience experiments. To this end, I\u0026rsquo;m e.g., working on MRI aqusition parameters and sequences (for example ISSS \u0026amp; multiband) and a small toolbox that allows audiometry measurements in the MRI environment (corresponding OSF page).\n","date":1554868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554868800,"objectID":"2e91946cfca51163347e0d3f3c748b87","permalink":"https://peerherholz.github.io/project/tools/","publishdate":"2019-04-10T00:00:00-04:00","relpermalink":"/project/tools/","section":"project","summary":"Auditory neurosciene is hard, let's ease it up a bit.","tags":["tools auditory neuroscience"],"title":"tools for auditory neuroscience","type":"project"},{"authors":["Michael Notter","Dan Gale","Peer Herholz","Ross Markello","Marie-Laure Notter-Bielser","Kirstie Whitaker"],"categories":null,"content":"","date":1550984400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550984400,"objectID":"c0fdb3662335624c26dcbbe473b5d5a3","permalink":"https://peerherholz.github.io/publication/atlasreader/","publishdate":"2019-02-24T00:00:00-05:00","relpermalink":"/publication/atlasreader/","section":"publication","summary":"A major advantage of magnetic resonance imaging (MRI) over other neuroimaging methods is its capability to noninvasively locate a region of interest (ROI) in the human brain. For example, using functional MRI, we are able to pinpoint where in the brain a cognitive task elicits higher activation relative to a control. But just knowing the Cartesian coordinate of such a ROI is not useful if we cannot assign it a neuroanatomical label. For this reason, MRI images are usually normalized into a common template space (Fonov et al., 2011), where well-established atlases can be used to associate a given coordinate with the label of a brain region. Most major neuroimaging software packages provide some functionality to locate the main peaks of an ROI but this functionality is often restricted to a few atlases, frequently requires manual intervention, does not give the user much flexibility in the output creation process, and never considers the full extent of the ROI. To tackle those shortcomings, we created AtlasReader, a Python interface for generating coordinate tables and region labels from statistical MRI images. With AtlasReader, users can use any of the freely and publicly available neuroimaging atlases, without any restrictionto their preferred software package, to create publication-ready output figures and tables that contain relevant information about the peaks and clusters extent of each ROI. To our knowledge, providing atlas information about the full extent of a cluster, i.e. over which atlas regions does a ROI extent, is a new feature that is not available in any other, comparable neuroimaging software package.","tags":null,"title":"AtlasReader: A Python package to generate coordinate tables, region labels, and informative figures from statistical MRI images","type":"publication"},{"authors":["Christoph Vogelbacher","Miriam HA Bopp","Verena Schuster","Peer Herholz","Jens Sommer","Andreas Jansen"],"categories":null,"content":"","date":1546318800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546318800,"objectID":"6d91c51a3312fff80eeda841ccccbfa0","permalink":"https://peerherholz.github.io/publication/labqa2go/","publishdate":"2019-01-01T00:00:00-05:00","relpermalink":"/publication/labqa2go/","section":"publication","summary":"Image characteristics of magnetic resonance imaging (MRI) data (e.g. signal-to-noise ratio, SNR) may change over the course of a study. To monitor these changes a quality assurance (QA) protocol is necessary. QA can be realized both by performing regular phantom measurements and by controlling the human MRI datasets (e.g. noise detection in structural or movement parameters in functional datasets). Several QA tools for the assessment of MRI data quality have been developed. Many of them are freely available. This allows in principle the flexible set-up of a QA protocol specifically adapted to the aims of one's own study. However, setup and maintenance of these tools bind time, in particular since the installation and operation often require a fair amount of technical knowledge. In this article we present a light-weighted virtual machine, named LAB–QA2GO, which provides scripts for fully automated QA analyses of phantom and human datasets. This virtual machine is ready for analysis by starting it the first time. With minimal configuration in the guided web-interface the first analysis can start within 10 minutes, while adapting to local phantoms and needs is easily possible. The usability and scope of LAB–QA2GO is illustrated using a data set from the QA protocol of our lab. With LAB–QA2GO we hope to provide an easy-to-use toolbox that is able to calculate QA statistics without high effort.","tags":null,"title":"LAB–QA2GO: A free, easy-to-use toolbox for the quality assessment of magnetic resonance imaging data","type":"publication"},{"authors":["James Kent","Peer Herholz"],"categories":null,"content":"","date":1546318800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546318800,"objectID":"2d5988de4ba2eacae78266265f166978","permalink":"https://peerherholz.github.io/publication/nibeta/","publishdate":"2019-01-01T00:00:00-05:00","relpermalink":"/publication/nibeta/","section":"publication","summary":"You may not be aware of it, but your brain is orchestrating a complex ballet of activity while reading this sentence. Whether it is following a dot or reading a sentence; the brain is evaluating input and sending motoric output to perform optimally/efficiently. We can measure this flurry of activity using functional Magnetic Resonance Imaging (fMRI). Traditional fMRI analysis emphasizes what regions are “activated/deactivated” during a task, but it does not provide information about which regions are acting in synchrony or are being segregated. Knowing the synchronous/segregated brain regions during a task gives insights on the potential organization of the brain. NiBetaSeries seeks to provide information about the organization of the brain by correlating activation/deactivation patterns between brain regions during a task.","tags":null,"title":"LAB–QA2GO: A free, easy-to-use toolbox for the quality assessment of magnetic resonance imaging data","type":"publication"},{"authors":["Verena Schuster","Peer Herholz","Kristin M Zimmermann","Stefan Westermann","Stefan Frässle","Andreas Jansen"],"categories":null,"content":"","date":1508731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508731200,"objectID":"868ae085d3b83d49b1cf5ee0309abb11","permalink":"https://peerherholz.github.io/publication/relia-visuo/","publishdate":"2017-10-23T00:00:00-04:00","relpermalink":"/publication/relia-visuo/","section":"publication","summary":"The development of brain imaging techniques, in particular functional magnetic resonance imaging (fMRI), made it possible to non-invasively study the hemispheric lateralization of cognitive brain functions in large cohorts. Comprehensive models of hemispheric lateralization are, however, still missing and should not only account for the hemispheric specialization of individual brain functions, but also for the interactions among different lateralized cognitive processes (e.g., language and visuospatial processing). This calls for robust and reliable paradigms to study hemispheric lateralization for various cognitive functions. While numerous reliable imaging paradigms have been developed for language, which represents the most prominent left-lateralized brain function, the reliability of imaging paradigms investigating typically right-lateralized brain functions, such as visuospatial processing, has received comparatively less attention. In the present study, we aimed to establish an fMRI paradigm that robustly and reliably identifies right-hemispheric activation evoked by visuospatial processing in individual subjects. In a first study, we therefore compared three frequently used paradigms for assessing visuospatial processing and evaluated their utility to robustly detect right-lateralized brain activity on a single-subject level. In a second study, we then assessed the test-retest reliability of the so-called Landmark task–the paradigm that yielded the most robust results in study 1. At the single-voxel level, we found poor reliability of the brain activation underlying visuospatial attention. This suggests that poor signal-to-noise ratios can become a limiting factor for test-retest reliability. This represents a common detriment of fMRI paradigms investigating visuospatial attention in general and therefore highlights the need for careful considerations of both the possibilities and limitations of the respective fMRI paradigm–in particular, when being interested in effects at the single-voxel level. Notably, however, when focusing on the reliability of measures of hemispheric lateralization (which was the main goal of study 2), we show that hemispheric dominance (quantified by the lateralization index, LI, with |LI| 0.4) of the evoked activation could be robustly determined in more than 62% and, if considering only two categories (i.e., left, right), in more than 93% of our subjects. Furthermore, the reliability of the lateralization strength (LI) was “fair” to “good”. In conclusion, our results suggest that the degree of right-hemispheric dominance during visuospatial processing can be reliably determined using the Landmark task, both at the group and single-subject level, while at the same time stressing the need for future refinements of experimental paradigms and more sophisticated fMRI data acquisition techniques.","tags":null,"title":"Comparison of fMRI paradigms assessing visuospatial processing: Robustness and reproducibility","type":"publication"}]